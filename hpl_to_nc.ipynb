{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509d11a6-51af-47cc-a68d-a34fb8d6b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1412f73a-af74-4333-a0a8-6a77e0bcff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpl_header(file_path,header_n=17):\n",
    "    #import hpl files into intercal storage\n",
    "    #header_n is the length of header\n",
    "    with open(file_path, 'r') as text_file:\n",
    "        lines=text_file.readlines()\n",
    "\n",
    "    #write lines into Dictionary\n",
    "    data_temp=dict()\n",
    "    data_temp['header_n'] = header_n\n",
    "    data_temp['filename']=lines[0].split()[-1]\n",
    "    data_temp['system_id']=int(lines[1].split()[-1])\n",
    "    data_temp['number_of_gates']=int(lines[2].split()[-1])\n",
    "    data_temp['range_gate_length_m']=float(lines[3].split()[-1])\n",
    "    data_temp['gate_length_pts']=int(lines[4].split()[-1])\n",
    "    data_temp['pulses_per_ray']=int(lines[5].split()[-1])\n",
    "    data_temp['number_of_waypoints_in_file']=int(lines[6].split()[-1])\n",
    "    rays_n=(len(lines)-header_n)/(data_temp['number_of_gates']+1)\n",
    "    \n",
    "    '''\n",
    "    number of lines does not match expected format if the number of range gates \n",
    "    was changed in the measuring period of the data file (especially possible for stare data)\n",
    "    '''\n",
    "    if not rays_n.is_integer():\n",
    "        #print('Number of lines does not match expected format')\n",
    "        return np.nan\n",
    "    \n",
    "    data_temp['no_of_rays_in_file']=int(rays_n)\n",
    "    data_temp['scan_type']=''.join(lines[7].split()[2:])\n",
    "    data_temp['focus_range']=lines[8].split()[-1]\n",
    "    data_temp['start_time']=pd.to_datetime(' '.join(lines[9].split()[-2:]))\n",
    "    data_temp['resolution']=('%s %s' % (lines[10].split()[-1],'m s-1'))\n",
    "    data_temp['range_gates']=np.arange(0,data_temp['number_of_gates'])\n",
    "    \n",
    "    if data_temp['scan_type'].endswith(\"-overlapping\"):\n",
    "        # print(\"Gateoverlap turned on.\")\n",
    "        data_temp['center_of_gates']=data_temp['range_gate_length_m']/2 \\\n",
    "        + (data_temp['range_gates']*data_temp['range_gate_length_m']/data_temp['gate_length_pts'])\n",
    "    elif data_temp['scan_type'].endswith(\"-nonoverlapping\"):\n",
    "        # print(\"Gateoverlap turned off.\")\n",
    "        data_temp['center_of_gates']=(data_temp['range_gates']+0.5)*data_temp['range_gate_length_m']\n",
    "    else:\n",
    "        sys.exit(\"New string in the line Range of measurement (center of gate). Need to check!\")\n",
    "    return data_temp\n",
    "\n",
    "def convert_hpl_to_ncfiles(file_path,header_n=17,ray_min=5,subfolder=True,output_path=None):\n",
    "    #convert an hpl file into nc files and save them if save_file=True \n",
    "    #ray_min is the minimum rays needed in order to be considered as a scan block.\n",
    "    file_path = Path(file_path).absolute()\n",
    "    \n",
    "    if not file_path.name.endswith(\".hpl\"):\n",
    "        sys.exit(\"Wrong file. No hpl file was found.\")\n",
    "        \n",
    "    nc_folder_path = file_path.parent / file_path.stem\n",
    "    # if no specified output, then use the hpl file location as the default output location\n",
    "    if output_path == None:\n",
    "        file_path_prefix = nc_folder_path\n",
    "    else:\n",
    "        file_path_prefix = Path(output_path).absolute() / nc_folder_path.stem\n",
    "        \n",
    "    #if subfolder is True, save the nc file into a subfolder named as the hpl file name\n",
    "    if  subfolder == True:\n",
    "        if file_path_prefix.exists():\n",
    "            # should work on this in the next version to avoid overwrite nc files if they are already there.\n",
    "            print(\"Folder exists. Should work on this in the next version to avoid overwrite nc files if they are already there.\")\n",
    "        else:\n",
    "            file_path_prefix.mkdir(parents=True, exist_ok=False)\n",
    "    \n",
    "    #file_header = hpl_header(file_path,header_n=header_n)\n",
    "    block_info,file_header=get_data_block_headers(file_path,header_n=header_n)\n",
    "    scan_block_idx_array=get_scan_blocks(block_info)\n",
    "\n",
    "    with open(file_path, 'r') as text_file:\n",
    "        lines=text_file.readlines()\n",
    "        if scan_block_idx_array.shape[0] == 0:\n",
    "            scanblock_to_nc(lines,file_header,block_info,0,block_info['block_header_line_num'].shape[0],file_path_prefix=file_path_prefix) \n",
    "        for i in range(0,scan_block_idx_array.shape[0]):\n",
    "            if subfolder == True:\n",
    "                file_path_prefix_tmp = file_path_prefix / (file_path_prefix.name +\"_{}_\".format(i))\n",
    "            else:\n",
    "                file_path_prefix_tmp = file_path_prefix.parent / (file_path_prefix.name +\"_{}_\".format(i))\n",
    "            if scan_block_idx_array.shape[0] == 1:\n",
    "                scanblock_to_nc(lines,file_header,block_info,scan_block_idx_array[i],block_info['block_header_line_num'].shape[0],file_path_prefix=file_path_prefix_tmp) \n",
    "            elif i < (scan_block_idx_array.shape[0]-1) and (scan_block_idx_array[i+1] - scan_block_idx_array[i]>ray_min):\n",
    "                scanblock_to_nc(lines,file_header,block_info,scan_block_idx_array[i],scan_block_idx_array[i+1],file_path_prefix=file_path_prefix_tmp)\n",
    "            elif i == (scan_block_idx_array.shape[0]-1) and ((block_info['block_header_line_num'].shape[0]-1-scan_block_idx_array[i])>ray_min):\n",
    "                scanblock_to_nc(lines,file_header,block_info,scan_block_idx_array[i],block_info['block_header_line_num'].shape[0],file_path_prefix=file_path_prefix_tmp) \n",
    "\n",
    "def scanblock_to_nc(lines,file_header,block_info_dict,scan_block_start_index,scan_block_end_index,file_path_prefix,save_file=True):\n",
    "    #get one scan block from the hpl file to into an nc file\n",
    "    file_path_prefix = Path(file_path_prefix).absolute()\n",
    "    gates_num = file_header['number_of_gates']\n",
    "    ray_num = scan_block_end_index - scan_block_start_index\n",
    "    header_n = file_header['header_n']\n",
    "    data_temp = dict()\n",
    "    \n",
    "    #initialize\n",
    "    data_temp['radial_velocity'] = np.full([ray_num,gates_num],np.nan) #m s-1\n",
    "    data_temp['intensity'] = np.full([ray_num,gates_num],np.nan) #SNR+1\n",
    "    data_temp['beta'] = np.full([ray_num,gates_num],np.nan) #m-1 sr-1\n",
    "    data_temp['elevation'] = np.full(ray_num,np.nan) #degrees\n",
    "    data_temp['azimuth'] = np.full(ray_num,np.nan) #degrees\n",
    "    data_temp['time'] = np.full(ray_num,block_info_dict['time'][0]) \n",
    "    data_temp['pitch'] = np.full(ray_num,np.nan) #degrees\n",
    "    data_temp['roll'] = np.full(ray_num,np.nan) #degrees\n",
    "    \n",
    "    for i in range(0,ray_num): #loop rays\n",
    "        lines_temp = lines[header_n+(scan_block_start_index+i)*(gates_num+1)+1:header_n+(scan_block_start_index+i)*(gates_num+1)+gates_num+1]\n",
    "        # header_temp = np.asarray(lines[header_n+(i*gates_num)+i].split(),dtype=float)\n",
    "        data_temp['time'][i] = block_info_dict['time'][scan_block_start_index+i]\n",
    "        data_temp['azimuth'][i] = block_info_dict['azimuth'][scan_block_start_index+i]\n",
    "        data_temp['elevation'][i] = block_info_dict['elevation'][scan_block_start_index+i]\n",
    "        data_temp['pitch'][i] = block_info_dict['pitch'][scan_block_start_index+i]\n",
    "        data_temp['roll'][i] = block_info_dict['roll'][scan_block_start_index+i]\n",
    "        for j in range(0,gates_num): #loop range gates\n",
    "            line_temp=np.asarray(lines_temp[j].split(),dtype=float)\n",
    "            data_temp['radial_velocity'][i,j] = line_temp[1]\n",
    "            data_temp['intensity'][i,j] = line_temp[2]\n",
    "            data_temp['beta'][i,j] = line_temp[3]\n",
    "            if line_temp.size>4:\n",
    "                data_temp['spectral_width'][i,j] = line_temp[4]\n",
    "    \n",
    "    ds = xr.Dataset(coords={'time':data_temp['time'],\n",
    "                            'azimuth':(('time',),data_temp['azimuth']),\n",
    "                            'elevation':(('time',),data_temp['elevation']),\n",
    "                            'distance':file_header['center_of_gates'],\n",
    "                            'pitch':(('time',),data_temp['pitch']),\n",
    "                            'roll':(('time',),data_temp['roll']),\n",
    "                            },\n",
    "                    data_vars={'radial_velocity':(['time','distance'],\n",
    "                                                  data_temp['radial_velocity']),\n",
    "                               'beta': (('time','distance'), \n",
    "                                        data_temp['beta']),\n",
    "                               'intensity': (( 'time','distance'),\n",
    "                                             data_temp['intensity'])\n",
    "                              }\n",
    "                   )\n",
    "    if save_file == True:\n",
    "        ds.to_netcdf(file_path_prefix.parent / (file_path_prefix.name + \"{}-{}.nc\".format(scan_block_start_index,scan_block_end_index)))\n",
    "        ds.close()\n",
    "        return\n",
    "    else:\n",
    "        return ds\n",
    "    \n",
    "def get_data_block_headers(file_path,header_n=17):\n",
    "    #import hpl files into intercal storage\n",
    "    file_header = hpl_header(file_path,header_n=header_n)\n",
    "    with open(file_path, 'r') as text_file:\n",
    "        lines=text_file.readlines()\n",
    "    block_info = dict()\n",
    "    block_info['block_header_line_num'] = np.array([17+n*(file_header[\"number_of_gates\"]+1) \\\n",
    "                                                    for n in range(int(file_header['no_of_rays_in_file']))])\n",
    "    block_info['block_header_line'] = np.array([lines[i] for i in block_info['block_header_line_num']])\n",
    "    block_info['azimuth']= np.array([float(block_info['block_header_line'][i].split()[1]) for i in range(len(block_info['block_header_line']))])\n",
    "    block_info['elevation'] = np.array([float(block_info['block_header_line'][i].split()[2]) for i in range(len(block_info['block_header_line']))])\n",
    "\n",
    "\n",
    "    #use start time from file_header to get time info for each ray\n",
    "    block_info['time'] = [float(block_info['block_header_line'][i].split()[0]) for i in range(len(block_info['block_header_line']))]\n",
    "\n",
    "    block_info['time']=pd.to_timedelta([datetime.timedelta(seconds=x*60*60.0) for x in block_info['time']])\n",
    "\n",
    "    block_info['time'] = np.array(file_header['start_time'].floor('D') + block_info['time'])\n",
    "\n",
    "    block_info['pitch'] = np.array([float(block_info['block_header_line'][i].split()[3]) for i in range(len(block_info['block_header_line']))])\n",
    "    block_info['roll'] = np.array([float(block_info['block_header_line'][i].split()[4]) for i in range(len(block_info['block_header_line']))])\n",
    "    return block_info,file_header\n",
    "\n",
    "def get_scan_blocks(block_info_dict,interval_min=0.01):\n",
    "    # This function get the scan start block number index by looking at none move rays. \n",
    "    #interval_min is the minimal interval of the movement, smaller than which will be considered no move and will split the scans.\n",
    "    split_indicate_list = []\n",
    "    for i in range(len(block_info_dict['azimuth'])-1):\n",
    "        if (np.abs(block_info_dict['azimuth'][i+1] - block_info_dict['azimuth'][i]) < interval_min) and \\\n",
    "           (np.abs(block_info_dict['elevation'][i+1] - block_info_dict['elevation'][i]) < interval_min):\n",
    "            split_indicate_list.append(1)\n",
    "        else:\n",
    "            split_indicate_list.append(0)\n",
    "    block_index_array=np.where(np.array(split_indicate_list)==1)[0] #np.where will have two output here so need to use [0] to remove the second empty output.\n",
    "    if 0 not in block_index_array:\n",
    "        block_index_array=np.insert(block_index_array,0,0)\n",
    "    block_index_array = remove_continuous(block_index_array)\n",
    "    block_index_array = split_full_circles(block_info_dict,block_index_array)\n",
    "    return block_index_array\n",
    "\n",
    "def remove_continuous(array):\n",
    "    # initialize an empty list to store the result\n",
    "    result = []\n",
    "    # loop through the array\n",
    "    for i in range(len(array)):\n",
    "    # if the current element is the first one or not continuous with the previous one\n",
    "    # if use array[i] - array[i-1] < 3 below instead, it will also skip elements with differences smaller than 3.\n",
    "        if i == 0 or array[i] - array[i-1] !=1:\n",
    "        #append it to the result list\n",
    "            result.append(array[i])\n",
    "    # return the result\n",
    "    return np.array(result)\n",
    "\n",
    "def split_full_circles(block_info_dict,block_index_array):\n",
    "    #This should split the full circle scans into individual circle\n",
    "    for i in range(block_index_array.shape[0]):\n",
    "        if i < (block_index_array.shape[0]-1):\n",
    "            for j in range(block_index_array[i],block_index_array[i+1]):\n",
    "                if np.abs(block_info_dict['azimuth'][j] - block_info_dict['azimuth'][i]) >=360:\n",
    "                    block_index_array=np.insert(block_index_array,i+1,j)\n",
    "        elif block_index_array[i] < block_info_dict['azimuth'].shape[0]:\n",
    "            for j in range(block_index_array[i],block_info_dict['azimuth'].shape[0]):\n",
    "                if np.abs(block_info_dict['azimuth'][j] - block_info_dict['azimuth'][i]) >=360:\n",
    "                    block_index_array=np.insert(block_index_array, i+1,j)            \n",
    "    return block_index_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0ca7e-5ab2-4f0a-b0aa-a6eed990e39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 66/4950 [01:55<1:44:24,  1.28s/it]"
     ]
    }
   ],
   "source": [
    "input_path = \"/home/UOCNT/dli84/research/Bottle_lake/Field_data/Lidar_full_Burwood/Proc/2023/202305/202305*/\"\n",
    "input_files = sorted(glob(input_path+\"*.hpl\"))\n",
    "output_path = \"/home/UOCNT/dli84/research/Bottle_lake/Field_data/Lidar_full_Burwood/Proc/2023/netcdf/\"\n",
    "for file in tqdm(input_files, position=0, leave=True):\n",
    "    convert_hpl_to_ncfiles(file, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4d4eb-4235-439a-96a1-c03ec05c4a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (baseline)",
   "language": "python",
   "name": "baseline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
